{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SCPAnalysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import seaborn\n",
        "import re\n",
        "import pandas as pd\n",
        "import csv"
      ],
      "metadata": {
        "id": "SgKFVusK6r5S"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "u7sFuRy67AjR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKtEyQ0V7CVy",
        "outputId": "a79f702c-1e8c-45a3-8142-1823a28eb750"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wordcloud\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "KJR2jTMW_D52"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "ExcA-84R7LOB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load data from csv\n",
        "scp_df = pd.read_csv('scp6999.csv', header=0, delimiter=',', quoting=csv.QUOTE_ALL, encoding='utf-8', index_col=False, usecols=['code', 'title', 'text', 'link', 'rating'])\n",
        "\n",
        "scp_df.head # quick check - note excel limits will mean opening in excel will cause issues (cells running into others etc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GLyWRth7Pcz",
        "outputId": "14d272f7-47f6-47a7-97e4-60c934d44750"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of           code  ...  rating\n",
              "0      SCP-001  ...     NaN\n",
              "1      SCP-002  ...  1697.0\n",
              "2      SCP-003  ...   760.0\n",
              "3      SCP-004  ...  1091.0\n",
              "4      SCP-005  ...   640.0\n",
              "...        ...  ...     ...\n",
              "6994  SCP-6995  ...    55.0\n",
              "6995  SCP-6996  ...   327.0\n",
              "6996  SCP-6997  ...    96.0\n",
              "6997  SCP-6998  ...   129.0\n",
              "6998  SCP-6999  ...   546.0\n",
              "\n",
              "[6999 rows x 5 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setting up some functions for later use - each takes single string of words space separated, including if prefiltered by pos"
      ],
      "metadata": {
        "id": "9YM8kw3J8hsf"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def quick_clean(text):\n",
        "  text = text.lower()\n",
        "  clean_text = re.sub('[^a-zA-Z ]', '', text)\n",
        "  return clean_text"
      ],
      "metadata": {
        "id": "R9PpcUnF-ocm"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords(text):\n",
        "  return \" \".join([i for i in text.split() if i not in stopwords])"
      ],
      "metadata": {
        "id": "8fZXb5DB-oem"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pos_tag(text):\n",
        "  return nltk.pos_tag(text.split())"
      ],
      "metadata": {
        "id": "bkj_shi8-t00"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_wordcloud(text):\n",
        "  wordcloud = WordCloud(max_font_size=80, max_words=50, background_color=\"white\").generate(text)\n",
        "  plt.figure()\n",
        "  plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "  plt.axis(\"off\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "ZNrah81F-83b"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_most_common(text):\n",
        "  text = text.split()\n",
        "  word_counts = {}\n",
        "  for i in text:\n",
        "    word_counts[i] = text.count(i)\n",
        "  return sorted(word_counts.items(), key=lambda item: item[1], reverse=True)[:20]"
      ],
      "metadata": {
        "id": "fwlrH_X6_l85"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_most_common(text, label='Word'):\n",
        "  bar = seaborn.barplot([i[1] for i in text], [i[0] for i in text], orient= 'h')\n",
        "  seaborn.despine(left=True, bottom=True)\n",
        "  bar.set_xlabel('Frequency')\n",
        "  bar.set_ylabel(label)"
      ],
      "metadata": {
        "id": "0V42ka0P_rH5"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Title Analysis\n",
        "\n",
        "Examining the text titles of SCP articles from the main series 1 to 7"
      ],
      "metadata": {
        "id": "fcAAUpwM-Sli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7Rogvzv3-goZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}