{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SCPScrapingClean.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup, SoupStrainer\n",
        "import httplib2\n",
        "import re\n",
        "import pandas as pd\n",
        "from itertools import chain"
      ],
      "metadata": {
        "id": "yuvlEggrw2N7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scp_main_df = pd.DataFrame(columns=['code', 'title', 'text', 'link'], index=None)"
      ],
      "metadata": {
        "id": "IaESIR7f5MGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "http = httplib2.Http()"
      ],
      "metadata": {
        "id": "KA-qlOac-t3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "status, response = http.request('https://scp-wiki.wikidot.com/scp-series')\n",
        "soup = BeautifulSoup(response, 'html.parser')\n",
        "\n",
        "# the page links all follow pattern and can loop through nums to string just zero padded basically\n",
        "for i in range(1,1000):\n",
        "  num_as_str = '{}{}'.format('0' * (3 - len(str(i))) , str(i))\n",
        "  url = 'https://scp-wiki.wikidot.com/scp-{}'.format(num_as_str)\n",
        "  status, response = http.request(url)\n",
        "  soup = BeautifulSoup(response, 'html.parser')\n",
        "  text = \" \\n\".join([i.text for i in soup.find(id = 'page-content').find_all('p')])\n",
        "  # p tags include things like image captions may want to exclude, can do with scp-image-caption class there and check other cases\n",
        "  status, response = http.request('https://scp-wiki.wikidot.com/scp-series')\n",
        "  soup = BeautifulSoup(response, 'html.parser')\n",
        "  title = soup.find('a', text='SCP-{}'.format(num_as_str)).parent.text.split(\" - \")[-1]\n",
        "  # print(title)\n",
        "\n",
        "  info = ['SCP-{}'.format(num_as_str), title, text, url]\n",
        "  scp_main_df.loc[len(scp_main_df)] = info\n",
        "\n"
      ],
      "metadata": {
        "id": "-ul7CD-y-rGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scp_main_df.head"
      ],
      "metadata": {
        "id": "AV2D8U3dAUdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scp_main_df.to_csv('scp999.csv', sep='|')"
      ],
      "metadata": {
        "id": "rOXWeqEWAcY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_csv('scp999.csv', delimiter='|')"
      ],
      "metadata": {
        "id": "mffZktPsDxoA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}