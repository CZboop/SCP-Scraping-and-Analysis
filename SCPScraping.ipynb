{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SCPScrapingClean.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup, SoupStrainer\n",
        "import httplib2\n",
        "import re\n",
        "import pandas as pd\n",
        "from itertools import chain\n",
        "import time "
      ],
      "metadata": {
        "id": "yuvlEggrw2N7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setting up dataframe with columns required\n",
        "scp_main_df = pd.DataFrame(columns=['code', 'title', 'text', 'image captions', 'link', 'rating', 'state'], index=None)"
      ],
      "metadata": {
        "id": "IaESIR7f5MGs"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "http = httplib2.Http()"
      ],
      "metadata": {
        "id": "KA-qlOac-t3P"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the page links all follow pattern and can loop through nums to string just zero padded\n",
        "\n",
        "# note from 2235 onwards there are a couple that do not have the standard codes in directory pages, will keep the standard code for now\n",
        "# also some marked as missing from site or along those lines, probably added placeholder text, may want to add flag for easy filtering out\n",
        "\n",
        "for n in range(1,7000):\n",
        "  # timeout to limit load on the site (based on api requests per minute limit)\n",
        "  if n % 240 == 0:\n",
        "    print(n)\n",
        "    time.sleep(60)\n",
        "\n",
        "  # getting the number as a string in the way need to get url\n",
        "  num_as_str = '{}{}'.format('0' * (3 - len(str(n))), str(n)) if n < 1000 else str(n)\n",
        "\n",
        "  # requesting page for current/target scp, parsing with beautifulsoup\n",
        "  url = 'https://scp-wiki.wikidot.com/scp-{}'.format(num_as_str)\n",
        "  status, response = http.request(url)\n",
        "  soup = BeautifulSoup(response, 'html.parser')\n",
        "\n",
        "  captions = []\n",
        "  state = None\n",
        "  rating = None\n",
        "\n",
        "  if soup.find('div', {'id': 'u-adult-warning'}) != None:\n",
        "    url = 'https://scp-wiki.wikidot.com/adult:scp-{}/noredirect/true'.format(num_as_str)\n",
        "\n",
        "    status, response = http.request(url)\n",
        "    soup_adult = BeautifulSoup(response)\n",
        "\n",
        "    state = \"age restricted\"\n",
        "\n",
        "    rating_tag = soup_adult.find(class_ = 'number prw54353')\n",
        "\n",
        "    if rating_tag != None:\n",
        "      rating = rating_tag.text  \n",
        "\n",
        "    text = [i for i in soup_adult.find(id = 'page-content').find_all('p')]\n",
        "  else:\n",
        "    # getting text for the scp within the main content div\n",
        "    text = [i for i in soup.find(id = 'page-content').find_all('p')]\n",
        "    \n",
        "\n",
        "  # p tags include image captions which are excluded as below, may be other similar cases left in\n",
        "  for i in text:\n",
        "    try:\n",
        "      if i.parent.attrs['class'][0] == 'scp-image-caption':\n",
        "        captions.append(i.parent.attrs['class'][0])\n",
        "        text.remove(i)\n",
        "    except:\n",
        "      pass\n",
        "      \n",
        "  # getting text from result set\n",
        "  text = [i.text for i in text]\n",
        "\n",
        "  # getting the rating - a few do not have this primarily the ones that are 'blocked' or similar\n",
        "  if rating == None: # accounting for age restricted ones that already have ratings for w different method\n",
        "    rating = soup.find(class_ = 'number prw54353')\n",
        "    if rating == None:\n",
        "      pass\n",
        "    else:\n",
        "      rating = rating.text\n",
        "\n",
        "  # accounting for different directory pages (used to get title) based on number - getting correct url below\n",
        "  if n < 1000:\n",
        "    status, response = http.request('https://scp-wiki.wikidot.com/scp-series')\n",
        "  else:\n",
        "    status, response = http.request('https://scp-wiki.wikidot.com/scp-series-{}'.format(str(int(n//1000)+1)))\n",
        "\n",
        "  # requesting directory page\n",
        "  soup = BeautifulSoup(response, 'html.parser')\n",
        "\n",
        "  # some logic to get the text title (not scp number code) \n",
        "  # using next or previous siblings and numbers where needed as some have no code on the directory page or multiple codes\n",
        "  if soup.find('a', text='SCP-{}'.format(num_as_str)) == None:\n",
        "    # checks here due to cases where no previous or next sibling for one of the elements involved\n",
        "    if soup.find('a', text='SCP-{}'.format(str(n-1))) != None and soup.find('a', text='SCP-{}'.format(str(n-1))).parent.find_next_sibling() != None:\n",
        "      title = soup.find('a', text='SCP-{}'.format(str(n-1))).parent.find_next_sibling().text.split(\" - \")[-1]\n",
        "    else:\n",
        "      title = soup.find('a', text='SCP-{}'.format(str(n+1))).parent.find_previous_sibling().text\n",
        "      # removing the code part of titles that do have a code here\n",
        "      if ' - ' in title:\n",
        "        title = title.split(\" - \")[-1]\n",
        "    # could potentially add both codes for those that have two\n",
        "  # basic title finder for most cases\n",
        "  else:\n",
        "    title = soup.find('a', text='SCP-{}'.format(num_as_str)).parent.text.split(\" - \")[-1]\n",
        "  \n",
        "  # quotes to preserve commas and not cause csv issues - joining up p tags with newlines\n",
        "  text = \"\\\"{}\\\"\".format(\" \\n \".join(i for i in text))\n",
        "\n",
        "  captions = \"\\\"{}\\\"\".format(\" \\n \".join(i for i in captions))\n",
        "\n",
        "  # setting status - active, deleted, blocked, age restricted, clearance required\n",
        "  if state: # age restricted will already have been assigned\n",
        "    pass\n",
        "  elif \"This page may have been moved or deleted\" in text:\n",
        "    state = \"deleted\"\n",
        "  elif \"[Blocked]\" in title:\n",
        "    state = \"blocked\"\n",
        "  else:\n",
        "    state = \"active\" # at the moment this is catching some anomalies too...\n",
        "  \n",
        "\n",
        "  info = ['SCP-{}'.format(num_as_str), \"\\\"{}\\\"\".format(title), text, captions, url, rating, state]\n",
        "  scp_main_df.loc[len(scp_main_df)] = info\n",
        "\n"
      ],
      "metadata": {
        "id": "-ul7CD-y-rGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list([i for i in scp_main_df['image captions'] if len(i)>3])"
      ],
      "metadata": {
        "id": "AV2D8U3dAUdT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92309321-6274-4ef7-e52b-2a7ea234374c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scp_main_df.to_csv('scp6999morecols.csv', index=False) "
      ],
      "metadata": {
        "id": "rOXWeqEWAcY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WBnqE-EQIMuG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}