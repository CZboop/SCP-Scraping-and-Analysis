{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SCPScrapingClean.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup, SoupStrainer\n",
        "import httplib2\n",
        "import re\n",
        "import pandas as pd\n",
        "from itertools import chain\n",
        "import time "
      ],
      "metadata": {
        "id": "yuvlEggrw2N7"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scp_main_df = pd.DataFrame(columns=['code', 'title', 'text', 'link', 'rating'], index=None)"
      ],
      "metadata": {
        "id": "IaESIR7f5MGs"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "http = httplib2.Http()"
      ],
      "metadata": {
        "id": "KA-qlOac-t3P"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "status, response = http.request('https://scp-wiki.wikidot.com/scp-series')\n",
        "soup = BeautifulSoup(response, 'html.parser')\n",
        "\n",
        "# note from 2235 onwards there are a couple that do not have the standard codes in directory pages, will keep the standard code for now\n",
        "# may go back and adjust \n",
        "\n",
        "#note need to rejoin the text into a single string maybe with newlines, currently a list of each p tag contents\n",
        "# also 5257 and 5258 actually seem to not be working atm but placeholder text used on site prob added instead\n",
        "\n",
        "# the page links all follow pattern and can loop through nums to string just zero padded basically\n",
        "for n in range(6900,7000):\n",
        "  # timeout to limit load on the site\n",
        "  if n % 240 == 0:\n",
        "    print(n)\n",
        "    time.sleep(60)\n",
        "  num_as_str = '{}{}'.format('0' * (3 - len(str(n))), str(n)) if n < 1000 else str(n)\n",
        "\n",
        "  url = 'https://scp-wiki.wikidot.com/scp-{}'.format(num_as_str)\n",
        "  status, response = http.request(url)\n",
        "  soup = BeautifulSoup(response, 'html.parser')\n",
        "  text = [i for i in soup.find(id = 'page-content').find_all('p')]\n",
        "  # p tags include things like image captions may want to exclude, can do with scp-image-caption class there and check other cases\n",
        "  for i in text:\n",
        "    if hasattr(i.parent, 'class'):\n",
        "      if i.parent.get(\"class\") == 'scp-image-caption':\n",
        "        text.remove(i)\n",
        "  text = [i.text for i in text]\n",
        "  rating = soup.find(class_ = 'number prw54353')\n",
        "  if rating == None:\n",
        "    pass\n",
        "  else:\n",
        "    rating = rating.text\n",
        "  # below needs to accoun for past 999\n",
        "  if n < 1000:\n",
        "    status, response = http.request('https://scp-wiki.wikidot.com/scp-series')\n",
        "  else:\n",
        "    status, response = http.request('https://scp-wiki.wikidot.com/scp-series-{}'.format(str(int(n//1000)+1)))\n",
        "  soup = BeautifulSoup(response, 'html.parser')\n",
        "  if soup.find('a', text='SCP-{}'.format(num_as_str)) == None:\n",
        "    # some contain the value but don't have sibling eg start of block of 100  can try and catch or tweak\n",
        "    # can try next li after previous num find? assuming there won't be any consecutive non standard titles...\n",
        "    if soup.find('a', text='SCP-{}'.format(str(n-1))) != None and soup.find('a', text='SCP-{}'.format(str(n-1))).parent.find_next_sibling() != None:\n",
        "      title = soup.find('a', text='SCP-{}'.format(str(n-1))).parent.find_next_sibling().text.split(\" - \")[-1]\n",
        "    else:\n",
        "      title = soup.find('a', text='SCP-{}'.format(str(n+1))).parent.find_previous_sibling().text\n",
        "      if ' - ' in title:\n",
        "        title = title.split(\" - \")[-1]\n",
        "    print(title)\n",
        "    # and here can also change/note the other code? if later want to add another column for these edge cases \n",
        "    # eg the ozymandias effect is both scp2235 and ura9611\n",
        "  else:\n",
        "    title = soup.find('a', text='SCP-{}'.format(num_as_str)).parent.text.split(\" - \")[-1]\n",
        "  \n",
        "  # print(rating)\n",
        "  # quotes to preserve commas and not cause csv issues\n",
        "  info = ['SCP-{}'.format(num_as_str), \"\\\"{}\\\"\".format(title), \"\\\"{}\\\"\".format(text), url, rating]\n",
        "  scp_main_df.loc[len(scp_main_df)] = info\n",
        "\n"
      ],
      "metadata": {
        "id": "-ul7CD-y-rGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scp_main_df.head"
      ],
      "metadata": {
        "id": "AV2D8U3dAUdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scp_main_df.to_csv('scp6999.csv', mode='a', header=False) #should have done no index here as well"
      ],
      "metadata": {
        "id": "rOXWeqEWAcY0"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scp_df = pd.read_csv('scp6999.csv', delimiter=',', quotechar='\"')\n",
        "scp_df.columns = ['index', 'code', 'title', 'text', 'link', 'rating']\n"
      ],
      "metadata": {
        "id": "mffZktPsDxoA"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# some extra light  processing\n",
        "scp_df['text'] = scp_df['text'].apply(lambda x: \"\\\"{}\\\"\".format(\" \".join(i[1:-1] for i in x[2:-2].split(','))))\n"
      ],
      "metadata": {
        "id": "qtuihA3zPwv5"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# can also quick check if all ratings start with + and remove if so for easier comparisons, sorting etc\n",
        "# df auto switched to float, can do back to int and see if changes again... welp\n",
        "scp_df['rating'] = scp_df['rating'].apply(lambda x: int(x) if np.isnan(x)==False else x)\n",
        "           \n",
        "# maybe add a flag for ones that are inaccessible/deleted (title might be easy way to filter )\n",
        "scp_df.head"
      ],
      "metadata": {
        "id": "uyF-3deGdC-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scp_df.to_csv('scpjoinedtext.csv')"
      ],
      "metadata": {
        "id": "Q4kKQX5xRiZx"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(scp_df['text'][1])\n",
        "# may still have some issues with the join method?"
      ],
      "metadata": {
        "id": "4RuTzTpxea30"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}